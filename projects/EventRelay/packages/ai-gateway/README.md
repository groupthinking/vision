# @repo/ai-gateway

Multi-model AI gateway with automatic failover using Vercel AI SDK.

## Features

- ✅ **Multi-Model Support**: Grok, Claude, Gemini, OpenAI
- ✅ **Automatic Failover**: Seamless switching between providers
- ✅ **Type Safety**: Full TypeScript support
- ✅ **Streaming**: Support for streaming responses
- ✅ **Timeout Handling**: Configurable request timeouts
- ✅ **Error Recovery**: Graceful error handling with detailed logging

## Installation

```bash
npm install @repo/ai-gateway
```

## Usage

### Basic Text Generation

```typescript
import { AIGateway } from '@repo/ai-gateway';

const gateway = new AIGateway([
  {
    provider: 'grok',
    model: 'grok-beta',
    apiKey: process.env.XAI_API_KEY!,
  },
  {
    provider: 'claude',
    model: 'claude-3-5-sonnet-20241022',
    apiKey: process.env.ANTHROPIC_API_KEY!,
  },
  {
    provider: 'gemini',
    model: 'gemini-2.0-flash-exp',
    apiKey: process.env.GOOGLE_GENERATIVE_AI_API_KEY!,
  },
]);

const result = await gateway.generate({
  prompt: 'Explain quantum computing in simple terms',
  maxTokens: 500,
  temperature: 0.7,
});

console.log(result.text);
console.log(`Generated by: ${result.provider} (${result.model})`);
```

### Streaming Responses

```typescript
const stream = await gateway.stream({
  prompt: 'Write a creative story about AI',
  maxTokens: 1000,
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

### Custom Failover Order

```typescript
const gateway = new AIGateway(
  [
    { provider: 'claude', model: 'claude-3-5-sonnet-20241022', apiKey: '...' },
    { provider: 'gemini', model: 'gemini-2.0-flash-exp', apiKey: '...' },
    { provider: 'grok', model: 'grok-beta', apiKey: '...' },
  ],
  {
    fallbackOrder: ['claude', 'gemini', 'grok'], // Claude first
    maxRetries: 5,
    timeout: 60000, // 60 seconds
  }
);
```

### With System Prompts

```typescript
const result = await gateway.generate({
  system: 'You are a helpful AI assistant specialized in technical documentation.',
  prompt: 'Explain the difference between REST and GraphQL APIs',
  maxTokens: 800,
  temperature: 0.5,
});
```

### Integration with Next.js API Routes

```typescript
// app/api/generate/route.ts
import { AIGateway } from '@repo/ai-gateway';
import { NextRequest, NextResponse } from 'next/server';

const gateway = new AIGateway([
  { provider: 'grok', model: 'grok-beta', apiKey: process.env.XAI_API_KEY! },
  { provider: 'claude', model: 'claude-3-5-sonnet-20241022', apiKey: process.env.ANTHROPIC_API_KEY! },
]);

export async function POST(request: NextRequest) {
  const { prompt } = await request.json();

  try {
    const result = await gateway.generate({ prompt });
    return NextResponse.json(result);
  } catch (error) {
    return NextResponse.json(
      { error: 'All AI providers failed' },
      { status: 500 }
    );
  }
}
```

### Streaming in Next.js

```typescript
// app/api/stream/route.ts
import { AIGateway } from '@repo/ai-gateway';
import { NextRequest } from 'next/server';

const gateway = new AIGateway([...]);

export async function POST(request: NextRequest) {
  const { prompt } = await request.json();

  const stream = await gateway.stream({ prompt });

  const encoder = new TextEncoder();
  const readableStream = new ReadableStream({
    async start(controller) {
      for await (const chunk of stream.textStream) {
        controller.enqueue(encoder.encode(chunk));
      }
      controller.close();
    },
  });

  return new Response(readableStream, {
    headers: { 'Content-Type': 'text/plain; charset=utf-8' },
  });
}
```

## API Reference

### `AIGateway`

Main gateway class for managing multiple AI providers.

#### Constructor

```typescript
new AIGateway(configs: ModelConfig[], options?: AIGatewayConfig)
```

#### Methods

- `generate(options: GenerateOptions): Promise<GenerateResult>` - Generate text with failover
- `stream(options: GenerateOptions): Promise<StreamResult>` - Stream text with failover
- `getAvailableProviders(): AIProvider[]` - Get list of configured providers
- `hasProvider(provider: AIProvider): boolean` - Check if provider is available

### Types

```typescript
type AIProvider = 'grok' | 'claude' | 'gemini' | 'openai';

interface ModelConfig {
  provider: AIProvider;
  model: string;
  apiKey: string;
  maxTokens?: number;
  temperature?: number;
}

interface GenerateOptions {
  prompt: string;
  system?: string;
  maxTokens?: number;
  temperature?: number;
}

interface GenerateResult {
  text: string;
  provider: AIProvider;
  model: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}
```

## Environment Variables

```bash
# Required for each provider you want to use
XAI_API_KEY=your_grok_api_key
ANTHROPIC_API_KEY=your_claude_api_key
GOOGLE_GENERATIVE_AI_API_KEY=your_gemini_api_key
OPENAI_API_KEY=your_openai_api_key
```

## Architecture

- **Vercel AI SDK**: Unified interface for multiple AI providers
- **Automatic Failover**: Tries providers in order until success
- **Timeout Protection**: Prevents hanging requests
- **Type Safety**: Full TypeScript with generics
- **Error Handling**: Detailed error messages with provider context

## Model Defaults

- **Grok**: `grok-beta`
- **Claude**: `claude-3-5-sonnet-20241022`
- **Gemini**: `gemini-2.0-flash-exp`
- **OpenAI**: `gpt-4o`

## Related Packages

- `@repo/observability` - OpenTelemetry instrumentation
- `@repo/workflows` - Workflow.dev durable execution
- `@repo/mcp-connectors` - MCP protocol integrations

## Resources

- [Vercel AI SDK Docs](https://sdk.vercel.ai/docs)
- [Grok API Docs](https://docs.x.ai/api)
- [Anthropic API Docs](https://docs.anthropic.com/)
- [Google Generative AI Docs](https://ai.google.dev/)
