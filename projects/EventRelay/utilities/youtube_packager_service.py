#!/usr/bin/env python3
"""
YouTube Packager Service
========================
Production-ready service that transforms YouTube videos into structured learning packages.

Features:
- Pydantic schema enforcement for data validation
- Persistent storage with environment variable configuration
- Docker volume support for portability
- Comprehensive error handling and idempotency
- Event-driven architecture with message queue integration
"""

import os
import json
import asyncio
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
from dataclasses import asdict
import uuid

# Third-party imports
from pydantic import BaseModel, ValidationError, Field, field_validator
import aiofiles

# Local imports - using correct path to examples directory
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent / 'examples'))

from firecrawl_integration import (
    FirecrawlEnhancedPackager,
    VideoWebAnalysis,
    WebContent,
    integrate_firecrawl_with_packager
)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Environment configuration
STORAGE_PATH = os.getenv("YOUTUBE_PACKAGER_STORAGE_PATH", "./storage/video_packs")
TEMP_PATH = os.getenv("YOUTUBE_PACKAGER_TEMP_PATH", "./temp")
MESSAGE_QUEUE_URL = os.getenv("MESSAGE_QUEUE_URL", "redis://localhost:6379")
SERVICE_NAME = "youtube-packager"

from src.youtube_extension.processors.strategies import (
    VideoMetadata,
)
from src.youtube_extension.videopack.schema import (
    VideoPackV0 as YouTubeVideoPack,
    Transcript,
    TranscriptSegment,
    Keyframe,
    Requirement,
    CodeSnippet,
    ArtifactRef,
    Metrics,
    Provenance
)

class YouTubePackagerService:
    """Production-ready YouTube video packaging service"""

    def __init__(self, storage_path: Optional[str] = None, temp_path: Optional[str] = None, enable_firecrawl: bool = True):
        self.storage_path = Path(storage_path or STORAGE_PATH)
        self.temp_path = Path(temp_path or TEMP_PATH)
        self.enable_firecrawl = enable_firecrawl
        self.firecrawl_enhancer = FirecrawlEnhancedPackager() if enable_firecrawl else None
        self.ensure_directories()

    def ensure_directories(self):
        """Ensure required directories exist"""
        self.storage_path.mkdir(parents=True, exist_ok=True)
        self.temp_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"Storage path: {self.storage_path}")
        logger.info(f"Temp path: {self.temp_path}")

    async def check_existing_pack(self, job_id: str) -> Optional[Path]:
        """Check if a pack already exists for this job_id (idempotency)"""
        pack_file = self.storage_path / f"{job_id}_pack.json"
        if pack_file.exists():
            logger.info(f"Existing pack found for job_id: {job_id}")
            return pack_file
        return None

    async def save_pack(self, pack: YouTubeVideoPack, job_id: str) -> Path:
        """Save video pack to persistent storage"""
        try:
            # Create job-specific directory
            job_dir = self.storage_path / job_id
            job_dir.mkdir(exist_ok=True)

            # Save main pack file
            pack_file = job_dir / "pack.json"
            write_pack(pack_file, pack)

            # Save additional files
            await self._save_additional_files(pack, job_dir)

            logger.info(f"Pack saved successfully: {pack_file}")
            return pack_file

        except Exception as e:
            logger.error(f"Failed to save pack for job_id {job_id}: {e}")
            raise

    async def _save_additional_files(self, pack: YouTubeVideoPack, job_dir: Path):
        """Save additional files like README, code examples, etc."""

        # Generate README
        readme_content = self._generate_readme(pack)
        readme_file = job_dir / "README.md"

        async with aiofiles.open(readme_file, 'w') as f:
            await f.write(readme_content)

        # Save code examples if any
        if pack.content_structure.code_examples:
            code_dir = job_dir / "code_examples"
            code_dir.mkdir(exist_ok=True)

            for i, example in enumerate(pack.content_structure.code_examples):
                filename = example.get('filename', f'example_{i+1}.txt')
                code_file = code_dir / filename

                async with aiofiles.open(code_file, 'w') as f:
                    await f.write(example.get('code', ''))

        # Save learning guide
        guide_content = self._generate_learning_guide(pack)
        guide_file = job_dir / "learning_guide.md"

        async with aiofiles.open(guide_file, 'w') as f:
            await f.write(guide_content)

    def _generate_readme(self, pack: YouTubeVideoPack) -> str:
        """Generate README.md content"""
        video = pack.video_metadata
        analysis = pack.project_analysis

        readme = f"""# {video.title}

## Video Information
- **Channel**: {video.channel}
- **Duration**: {video.duration}
- **Video ID**: {video.video_id}

## Project Analysis
- **Type**: {analysis.project_type.title()}
- **Complexity**: {analysis.complexity_score:.1f}/1.0
- **Primary Language**: {analysis.tech_stack.primary_language}

## Learning Objectives
"""

        for obj in analysis.learning_objectives:
            readme += f"- **{obj.difficulty.title()}**: {obj.objective}\n"

        if analysis.prerequisites:
            readme += f"\n## Prerequisites\n"
            for prereq in analysis.prerequisites:
                readme += f"- {prereq}\n"

        if analysis.tech_stack.frameworks:
            readme += f"\n## Frameworks\n"
            for framework in analysis.tech_stack.frameworks:
                readme += f"- {framework}\n"

        readme += f"\n## Package Information\n"
        readme += f"- **Package ID**: {pack.metadata.package_id}\n"
        readme += f"- **Created**: {pack.metadata.created_at.strftime('%Y-%m-%d %H:%M:%S')}\n"
        readme += f"- **Version**: {pack.metadata.version}\n"

        return readme

    def _generate_learning_guide(self, pack: YouTubeVideoPack) -> str:
        """Generate learning guide content"""
        analysis = pack.project_analysis

        guide = f"""# Learning Guide: {pack.video_metadata.title}

## Overview
This guide will help you learn {analysis.tech_stack.primary_language} through the video content.

## Study Plan

### Phase 1: Preparation
"""

        if analysis.prerequisites:
            guide += "Before starting, ensure you have knowledge of:\n"
            for prereq in analysis.prerequisites:
                guide += f"- [ ] {prereq}\n"
        else:
            guide += "- [ ] Basic computer literacy\n"

        guide += f"""
### Phase 2: Learning Objectives
Complete these objectives in order:

"""

        for i, obj in enumerate(analysis.learning_objectives, 1):
            guide += f"{i}. **{obj.objective}** ({obj.difficulty})\n"
            if obj.estimated_time:
                guide += f"   - Estimated time: {obj.estimated_time}\n"
            guide += f"   - [ ] Completed\n\n"

        if pack.content_structure.key_concepts:
            guide += "### Phase 3: Key Concepts\n"
            guide += "Master these concepts:\n\n"
            for concept in pack.content_structure.key_concepts:
                guide += f"- [ ] {concept}\n"

        if pack.content_structure.practice_exercises:
            guide += f"\n### Phase 4: Practice Exercises\n"
            for i, exercise in enumerate(pack.content_structure.practice_exercises, 1):
                guide += f"{i}. {exercise.get('title', f'Exercise {i}')}\n"
                guide += f"   - {exercise.get('description', 'No description')}\n"
                guide += f"   - [ ] Completed\n\n"

        # Add web analysis resources if available
        if pack.web_analysis:
            guide += f"\n### Phase 5: Additional Resources\n"

            if pack.web_analysis.related_resources:
                guide += f"\n#### Related Tutorials:\n"
                for resource in pack.web_analysis.related_resources:
                    guide += f"- [{resource.get('title', 'Resource')}]({resource.get('url', '#')})\n"

            if pack.web_analysis.documentation:
                guide += f"\n#### Official Documentation:\n"
                for doc in pack.web_analysis.documentation:
                    guide += f"- [{doc.get('title', 'Documentation')}]({doc.get('url', '#')})\n"

            if pack.web_analysis.community_resources:
                guide += f"\n#### Community Resources:\n"
                for community in pack.web_analysis.community_resources:
                    guide += f"- [{community.get('title', 'Community Resource')}]({community.get('url', '#')})\n"

        return guide

    async def publish_event(self, event_type: str, job_id: str, payload: Dict[str, Any]):
        """Publish events to message queue"""
        try:
            # This would integrate with your actual message queue (Redis, RabbitMQ, etc.)
            event = {
                "event_type": event_type,
                "service": SERVICE_NAME,
                "job_id": job_id,
                "timestamp": datetime.now().isoformat(),
                "payload": payload
            }

            # For now, log the event (replace with actual queue publishing)
            logger.info(f"Publishing event: {event_type} for job_id: {job_id}")
            logger.debug(f"Event payload: {json.dumps(event, indent=2)}")

            # TODO: Implement actual message queue publishing
            # await message_queue.publish(event)

        except Exception as e:
            logger.error(f"Failed to publish event {event_type} for job_id {job_id}: {e}")

    async def create_sample_pack(self, video_id: str, job_id: str) -> YouTubeVideoPack:
        """Create a sample pack for testing (replace with actual video analysis)"""

        # This would be replaced with actual YouTube API calls and AI analysis
        transcript = Transcript(
            full_text="Welcome to this React patterns tutorial. Today we'll learn about Higher Order Components. First, let's set up our development environment. We'll start by creating a new React application",
            segments=[
                TranscriptSegment(idx=0, start_s=0.0, end_s=4.5, text="Welcome to this React patterns tutorial"),
                TranscriptSegment(idx=1, start_s=4.5, end_s=10.7, text="Today we'll learn about Higher Order Components"),
                TranscriptSegment(idx=2, start_s=10.7, end_s=16.5, text="First, let's set up our development environment"),
                TranscriptSegment(idx=3, start_s=16.5, end_s=23.6, text="We'll start by creating a new React application")
            ]
        )

        requirements = [
            Requirement(id="req_1", title="Set up React development environment", detail="Install Node.js, create React app, and set up development tools", priority="high"),
            Requirement(id="req_2", title="Implement Higher Order Component pattern", detail="Create a HOC for adding authentication logic", priority="medium")
        ]

        code_snippets = [
            CodeSnippet(path_hint="App.js", lang="javascript", content="import React from 'react';\n\nfunction App() {\n  return <h1>Hello React!</h1>;\n}\n\nexport default App;")
        ]

        pack = YouTubeVideoPack(
            video_id=video_id,
            transcript=transcript,
            requirements=requirements,
            code_snippets=code_snippets,
            provenance=Provenance(created_at=datetime.utcnow())
        )

        return pack

    async def run_packaging_job(self, job_id: str, video_url: str) -> Dict[str, Any]:
        """Main service function to run a packaging job"""

        try:
            logger.info(f"Starting packaging job: {job_id} for video: {video_url}")

            # Extract video ID from URL
            video_id = self._extract_video_id(video_url)
            if not video_id:
                raise ValueError(f"Invalid YouTube URL: {video_url}")

            # Check for existing pack (idempotency)
            existing_pack = await self.check_existing_pack(job_id)
            if existing_pack:
                await self.publish_event("project.completed", job_id, {
                    "status": "completed",
                    "pack_path": str(existing_pack),
                    "message": "Pack already exists (idempotent)"
                })
                return {
                    "status": "completed",
                    "pack_path": str(existing_pack),
                    "message": "Pack already exists"
                }

            # Publish started event
            await self.publish_event("project.started", job_id, {
                "video_url": video_url,
                "video_id": video_id
            })

            # Create the video pack (this would integrate with actual analysis services)
            pack = await self.create_sample_pack(video_id, job_id)

            # Enhance with Firecrawl web analysis if enabled
            if self.enable_firecrawl and self.firecrawl_enhancer:
                try:
                    logger.info("Enhancing pack with Firecrawl web analysis")
                    enhanced_pack_data = await integrate_firecrawl_with_packager(
                        pack.model_dump(), video_url
                    )

                    # Convert enhanced data back to Pydantic model
                    pack = YouTubeVideoPack(**enhanced_pack_data)
                    logger.info("Successfully enhanced pack with web analysis")

                except Exception as e:
                    logger.warning(f"Firecrawl enhancement failed, proceeding without: {e}")

            # Validate the pack against schema
            try:
                validated_pack = YouTubeVideoPack(**pack.model_dump())
            except ValidationError as e:
                error_msg = f"Pydantic Schema Validation Error: {str(e)}"
                logger.error(error_msg)

                await self.publish_event("project.failed", job_id, {
                    "error": error_msg,
                    "validation_errors": e.errors()
                })

                return {
                    "status": "failed",
                    "error": error_msg
                }

            # Save the pack
            pack_path = await self.save_pack(validated_pack, job_id)

            # Publish completion event
            await self.publish_event("project.completed", job_id, {
                "status": "completed",
                "pack_path": str(pack_path),
                "video_id": video_id,
                "package_id": validated_pack.metadata.package_id
            })

            logger.info(f"Packaging job completed successfully: {job_id}")

            return {
                "status": "completed",
                "pack_path": str(pack_path),
                "package_id": validated_pack.metadata.package_id,
                "video_id": video_id
            }

        except ValidationError as e:
            error_msg = f"Schema validation failed: {str(e)}"
            logger.error(error_msg)

            await self.publish_event("project.failed", job_id, {
                "error": error_msg,
                "error_type": "validation_error"
            })

            return {
                "status": "failed",
                "error": error_msg
            }

        except Exception as e:
            error_msg = f"Packaging job failed: {str(e)}"
            logger.error(error_msg)

            await self.publish_event("project.failed", job_id, {
                "error": error_msg,
                "error_type": "processing_error"
            })

            return {
                "status": "failed",
                "error": error_msg
            }

    def _extract_video_id(self, video_url: str) -> Optional[str]:
        """Extract YouTube video ID from URL"""
        import re

        patterns = [
            r'(?:youtube\.com/watch\?v=|youtu\.be/)([a-zA-Z0-9_-]{11})',
            r'youtube\.com/embed/([a-zA-Z0-9_-]{11})',
            r'youtube\.com/v/([a-zA-Z0-9_-]{11})'
        ]

        for pattern in patterns:
            match = re.search(pattern, video_url)
            if match:
                return match.group(1)

        return None

# Service factory function
def create_service() -> YouTubePackagerService:
    """Create and configure the YouTube Packager Service"""
    return YouTubePackagerService()

# Example usage and testing
async def main():
    """Example usage of the YouTube Packager Service"""

    # Create service
    service = create_service()

    # Example job
    job_id = "test_job_001"
    video_url = "https://www.youtube.com/watch?v=bMknfKXIFA8"

    print(f"ğŸ¯ YouTube Packager Service - Testing")
    print(f"Job ID: {job_id}")
    print(f"Video URL: {video_url}")
    print("=" * 60)

    # Run packaging job
    result = await service.run_packaging_job(job_id, video_url)

    print(f"\nğŸ“Š Result:")
    print(json.dumps(result, indent=2))

    if result["status"] == "completed":
        print(f"\nâœ… Success!")
        print(f"ğŸ“ Pack saved at: {result['pack_path']}")
        print(f"ğŸ†” Package ID: {result.get('package_id', 'N/A')}")

        # Test idempotency by running again
        print(f"\nğŸ”„ Testing idempotency...")
        result2 = await service.run_packaging_job(job_id, video_url)
        print(f"Second run result: {result2['status']}")
        print(f"Message: {result2.get('message', 'N/A')}")
    else:
        print(f"\nâŒ Failed: {result['error']}")

if __name__ == "__main__":
    asyncio.run(main())