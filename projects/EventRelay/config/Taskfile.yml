# UVAI Video Processing Pipeline Automation
# Taskfile for streamlined video-to-action processing

version: '3'

vars:
  VIDEO_PROCESSING_DIR: /Users/garvey/UVAI/02_CORE/youtube-extension
  MCP_SERVER_PORT: 8000
  PYTHON_ENV: python3

tasks:
  # Video Processing Pipeline Tasks
  
  install-deps:
    desc: Install all required dependencies for video processing
    cmds:
      - pip3 install youtube-transcript-api google-api-python-client yt-dlp mcp python-dotenv
      - pip3 install opentelemetry-api opentelemetry-sdk opentelemetry-auto-instrumentation
    sources:
      - requirements.txt
    generates:
      - .deps-installed

  start-mcp-server:
    desc: Start YouTube Extension MCP server
    deps: [install-deps]
    cmds:
      - cd {{.VIDEO_PROCESSING_DIR}} && {{.PYTHON_ENV}} mcp_server.py
    env:
      YOUTUBE_API_KEY: '{{.YOUTUBE_API_KEY}}'
      OPENAI_API_KEY: '{{.OPENAI_API_KEY}}'

  process-video:
    desc: Process YouTube video through complete pipeline
    deps: [install-deps]
    cmds:
      - cd {{.VIDEO_PROCESSING_DIR}} && {{.PYTHON_ENV}} -c "import asyncio; import sys; sys.path.append('/Users/garvey/UVAI/05_INFRASTRUCTURE/grok-claude-hybrid/src'); from youtube_innovation_learning_database import YouTubeInnovationLearningDB; import asyncio; async def process(){{ db = YouTubeInnovationLearningDB(); result = await db.intake_youtube_video_with_innovation({{'video_url':'{VIDEO_URL}','innovation_goal':'Extract actionable steps','pressure_level':1.0,'enable_breakthrough_detection':True}}); print('Video processed:', result) }}; asyncio.run(process())"
    vars:
      VIDEO_URL: "https://www.youtube.com/watch?v=2bGh_DlkubM"

  install-context7:
    desc: Install Context7 MCP server for API documentation
    cmds:
      - 'echo "Execute in Claude Code - claude mcp add transport http context7 https://github.com/upstash/context7"'
      - 'echo "Config file created at: {{.VIDEO_PROCESSING_DIR}}/config/context7_integration.json"'

  test-integrations:
    desc: Test all MCP server integrations
    deps: [install-deps]
    cmds:
      - cd {{.VIDEO_PROCESSING_DIR}} && {{.PYTHON_ENV}} -c "print('üß™ Testing MCP integrations...'); print('‚úÖ YouTube Extension MCP{{":"}} Available'); import os; print('‚úÖ Context7 config{{":"}} Ready for installation' if os.path.exists('config/context7_integration.json') else '‚ùå Context7 config{{":"}} Missing')"

  benchmark-performance:
    desc: Benchmark video processing performance
    deps: [install-deps]
    cmds:
      - cd {{.VIDEO_PROCESSING_DIR}} && {{.PYTHON_ENV}} -c "
        import time
        from youtube_transcript_api import YouTubeTranscriptApi
        
        video_id = '{{.VIDEO_ID | default \"2bGh_DlkubM\"}}'
        
        # Benchmark transcript extraction
        start = time.time()
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        end = time.time()
        
        print(f'üìä Performance Benchmark:')
        print(f'   Video ID: {video_id}')
        print(f'   Transcript segments: {len(transcript)}')
        print(f'   Processing time: {end-start:.3f} seconds')
        print(f'   Performance: {\"‚úÖ Under 2s\" if end-start < 2 else \"‚ö†Ô∏è Over 2s\"}')
        "

  setup-observability:
    desc: Setup OpenTelemetry observability for video processing
    deps: [install-deps]
    cmds:
      - pip3 install opentelemetry-distro opentelemetry-exporter-otlp
      - cd {{.VIDEO_PROCESSING_DIR}} && cat > observability_config.py << 'EOF'
        # OpenTelemetry Configuration for UVAI
        from opentelemetry import trace
        from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
        from opentelemetry.sdk.trace import TracerProvider
        from opentelemetry.sdk.trace.export import BatchSpanProcessor
        
        def setup_tracing():
            trace.set_tracer_provider(TracerProvider())
            tracer = trace.get_tracer_provider()
            
            otlp_exporter = OTLPSpanExporter(endpoint="http://localhost:4317")
            span_processor = BatchSpanProcessor(otlp_exporter)
            tracer.add_span_processor(span_processor)
            
            return trace.get_tracer(__name__)
        EOF
      - echo "‚úÖ Observability configuration created"

  full-pipeline:
    desc: Run complete video processing pipeline with observability
    deps: [install-deps, setup-observability]
    cmds:
      - task: benchmark-performance
      - task: process-video
      - task: test-integrations
      - echo "üéØ Full pipeline execution complete"

  clean:
    desc: Clean generated files and cache
    cmds:
      - rm -f .deps-installed
      - rm -rf __pycache__
      - rm -rf .pytest_cache
      - echo "üßπ Cleanup complete"

  help:
    desc: Show available tasks
    cmds:
      - task --list